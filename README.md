# Dissertation
My Ph.D. dissertation, with source latex in github.  
However, this is not an ending point but a starting point.

### News
Submitted the final version on Feb 24, 2020 and clear all work on Feb 25, 2020.
Passed the defense on Feb 10, 2020.

### Lifelong Representation Learning for NLP Applications
#### Introduction
Why I care about lifelong representation learning.

#### Lifelong Classification
Imagine a classification task with undecided classes at training stage. (Yes, we humans mostly do classification on the fly during inference.)
This is about our WWW19 [paper](https://arxiv.org/abs/1809.06004), with [code](https://github.com/howardhsu/Meta-Open-World-Learning)

#### Lifelong Word Representation Learning
learning domain word embeddings from a sequence of learning tasks, where a domain with small corpus can borrow word-level contexts from domains with bigger corpus.
This is about our IJCAI18 [paper](https://arxiv.org/abs/1805.09991).

#### Lifelong Contextualized Representation Learning
keep post-training, pre-tuning using BERT for domain tasks. This is about the NAACL19 [paper](https://www.aclweb.org/anthology/N19-1242/) and RCRC [paper](https://arxiv.org/abs/1902.00821) (with [data](https://github.com/howardhsu/RCRC)).

#### Lifelong Graph Representation Learning
(WIP)

#### NLP Applications
We adopt lifelong learning to many applications:  
Aspect-based Sentiment Analysis (ABSA),
Complementary Entity Recognition,  
Question Answering,  
Dialog System.  

#### Conclusion and Future work
Future directions I would like to explore (and collaborations, of course).
